# Llama 4 Maverick 17B 128E Instruct FP8
  
[Catalog](../../../../..) / [Providers](../../../..) / [github-models](../../..) / **Llama 4 Maverick 17B 128E Instruct FP8**


## 📋 Overview
  
- **ID**: `meta/llama-4-maverick-17b-128e-instruct-fp8`
- **Provider**: [github-models](../)
- **Context Window**: 128k tokens
- **Max Output**: 8k tokens
  
## 🎯 Capabilities
  
### Input/Output Modalities
  
No modality information available.
  
### Core Features
  
No feature information available.
  
### Response Delivery
  
No delivery information available.
  
## 🎛️ Generation Controls
  
No control information available.
  
## 💰 Pricing
  
*Pricing shown for github-models*
  
  
### Token Pricing
  
| Input | Output | Reasoning | Cache Read | Cache Write |
|---------|---------|---------|---------|---------|
| - | - | - | - | - |

  
## 📋 Metadata
  
**Created**: 2025-09-02 22:27:11 UTC
  
**Last Updated**: 2025-09-02 22:27:11 UTC
  
  
---
  
  
### Navigation

- [More models by github-models](../)
- [All Providers](../../../../../providers)
- [Back to Catalog](../../../../..)


---
_Last Updated: 2025-09-02 22:29:41 UTC | Generated by [Starmap](https://github.com/agentstation/starmap)_
