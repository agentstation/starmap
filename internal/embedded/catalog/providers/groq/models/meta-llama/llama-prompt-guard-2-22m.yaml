# meta-llama/llama-prompt-guard-2-22m - llama-prompt-guard-2-22m
id: meta-llama/llama-prompt-guard-2-22m
name: llama-prompt-guard-2-22m
authors:
- id: meta
  name: Meta

# Model features
features:
  modalities:
    input:
    - text
    output:
    - text

  # Core capabilities
  tool_calls: false
  tools: false
  tool_choice: false
  web_search: false
  attachments: false

  # Reasoning & Verbosity
  reasoning: false
  reasoning_effort: false
  reasoning_tokens: false
  include_reasoning: false
  verbosity: false

  # Generation control support flags
  temperature: true
  top_p: true
  top_k: false
  top_a: false
  min_p: false
  typical_p: false
  tfs: false
  max_tokens: true
  max_output_tokens: false
  stop: true
  stop_token_ids: false
  frequency_penalty: true
  presence_penalty: true
  repetition_penalty: false
  no_repeat_ngram_size: false
  length_penalty: false
  logit_bias: false
  bad_words: false
  allowed_tokens: false
  seed: true
  logprobs: false
  top_logprobs: false
  echo: false
  "n": false
  best_of: false
  mirostat: false
  mirostat_tau: false
  mirostat_eta: false
  contrastive_search_penalty_alpha: false
  num_beams: false
  early_stopping: false
  diversity_penalty: false

  # Response delivery
  format_response: false
  structured_outputs: true
  streaming: true

# Model limits
limits:
  context_window: 512
  output_tokens: 512

# Timestamps
created_at: 2025-09-04T14:31:06Z
updated_at: 2025-09-04T14:31:06Z
