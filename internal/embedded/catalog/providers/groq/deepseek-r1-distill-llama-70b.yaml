# deepseek-r1-distill-llama-70b - AI model
id: deepseek-r1-distill-llama-70b
name: deepseek-r1-distill-llama-70b
authors:
- id: deepseek / meta
  name: DeepSeek / Meta
  models: {}
  created_at: null
  updated_at: null

# Model features
features:
  modalities:
    input:
    - text
    output:
    - text
  # Core capabilities
  tool_calls: false
  tools: true
  tool_choice: true
  web_search: false
  attachments: false
  # Reasoning & Verbosity
  reasoning: false
  reasoning_effort: false
  reasoning_tokens: false
  include_reasoning: false
  verbosity: false
  # Generation control support flags
  temperature: true
  top_p: true
  top_k: false
  top_a: false
  min_p: false
  typical_p: false
  tfs: false
  max_tokens: true
  max_output_tokens: false
  stop: true
  stop_token_ids: false
  frequency_penalty: true
  presence_penalty: true
  repetition_penalty: false
  no_repeat_ngram_size: false
  length_penalty: false
  logit_bias: false
  bad_words: false
  allowed_tokens: false
  seed: true
  logprobs: false
  top_logprobs: false
  echo: false
  "n": false
  best_of: false
  mirostat: false
  mirostat_tau: false
  mirostat_eta: false
  contrastive_search_penalty_alpha: false
  num_beams: false
  early_stopping: false
  diversity_penalty: false
  # Response delivery
  format_response: false
  structured_outputs: true
  streaming: true

# Model limits
limits:
  context_window: 131072
  output_tokens: 131072

# Timestamps
created_at: null
updated_at: null
